model:
    family: gpt2
    n_embd: 768
    n_layer: 12
    n_head: 12
    n_dims: 20
    n_positions: 101

training:
    data: gaussian
    task: linear_regression_large
    task_kwargs: {}
    batch_size: 64
    learning_rate: 0.0001
    save_every_steps: 1000
    keep_every_steps: 100000
    train_steps: 500001
    curriculum:
        points:
            start: 11
            end: 41
            inc: 2
            interval: 2000
        dims:
            start: 5
            end: 20
            inc: 1
            interval: 2000


out_dir: ../models/linear_regression_large

wandb:
    name: "linear_regression_large"
    project: icl-numerical-solvers
    entity: baojian-fudan-university
    notes: This config tries to replicate results in linear regression setting.
    log_every_steps: 100
